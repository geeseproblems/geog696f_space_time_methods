{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the nice things about Python (and Jupyter notebooks) is that we can write functions 'on the fly' and apply them to our data.  This can simply the process of repetitive coding, give us clearer and more readable code, improve reprodcibility, and allow us to make up for the shortcomings of built-in functions. \n",
    "\n",
    "This is an example from [pyOpenSci](https://github.com/pyOpenSci/) that shows the potential benefits of writing your own functions.  We're going to import using Pandas a simple CSV file that has a list of locations, columns with each location's average snowfall and temperature, and the country or geography region where the location can be found.  We'll then do some simple operations to group locations by their snowfall and look at their average temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data \n",
    "data_path = \"snow_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where the value in 'column1', the average snowfall, is greater than 10, and assign to a new DataFrame\n",
    "sites_more_snow = data[data[\"average_snowfall\"] > 15]\n",
    "\n",
    "# we can print this result now\n",
    "print(f\"Sites with more than 15 inches of snow: \\n{sites_more_snow}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then use the .mean method to get the average temperature for those sites \n",
    "avg_temp_more_snow = sites_more_snow[\"average_temperature\"].mean()\n",
    "print(f\"The mean temp for sites with more snow is {avg_temp_more_snow}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's find sites with a small accumulation of snow on average and once again calculate the average temperature for those sites\n",
    "sites_less_snow = data[data[\"average_snowfall\"] < 5]\n",
    "avg_temp_less_snow = sites_less_snow[\"average_temperature\"].mean()\n",
    "\n",
    "print(f\"The mean temp for sites with less snow is {avg_temp_less_snow}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's filter rows where the average snowfall is between 5 and 15 inches\n",
    "sites_medium_snow = data[(data[\"average_snowfall\"] >= 5) & (data[\"average_snowfall\"] <= 15)]\n",
    "\n",
    "print(f\"Sites with snowfall between 5 and 15 inches:\\n{sites_medium_snow}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And calculate the mean temperature for sites with medium snow\n",
    "avg_temp_medium_snow = sites_medium_snow[\"average_temperature\"].mean()\n",
    "print(\n",
    "    f\"The mean temperature for sites with medium snow is {avg_temp_medium_snow}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there a 'cleaner' way?\n",
    "\n",
    "That worked, but it was repetitive and a little mind numbing.  We did a few different things over and over again - we filtered the list by average snowfall, saved those rows as a new DataFrame, and then calculated the average temperature for those sites.  \n",
    "\n",
    "Here's an alternative approach using a set of simple functions to do the repetitive work for us.  Once again, this is from [pyOpenSci](https://github.com/pyOpenSci/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that reads in the data and replaces any missing data\n",
    "def load_data(filepath):\n",
    "\n",
    "    # Load the data and replace the missing value flag of -999 with NaN\n",
    "    return pd.read_csv(filepath, na_values=-999) # this is a Pandas function to read CSV data and deal with missing value flags\n",
    "\n",
    "\n",
    "# create a function that catagorizes a site by the amount of snow\n",
    "def categorize_snow(x):\n",
    "    if x > 15:\n",
    "        return \"High\"\n",
    "    elif x < 5:\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Medium\"\n",
    "\n",
    "# create a function that adds a column to our DataFrame with the snow catagory\n",
    "def add_snowfall_category(data):\n",
    "    data[\"snowfall_category\"] = data[\"average_snowfall\"].apply(categorize_snow) # note that this applies the function above this one to the data! \n",
    "    return data\n",
    "\n",
    "# Create a summary DataFrame that shows the characteristics of each group of locations in each snow category\n",
    "def summarize_data(data):\n",
    "    summary = data.groupby(\"snowfall_category\").agg(\n",
    "        avg_snowfall=(\"average_snowfall\", \"mean\"),\n",
    "        avg_temperature=(\"average_temperature\", \"mean\"),\n",
    "        site_count=(\"site\", \"count\"),\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the code cell above, those functions are now available to us in this session! In the code block below, we'll call those functions to do the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and deal with any missing data using the first function we wrote above\n",
    "data = load_data(data_path)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add snowfall category to our DataFrame using the third function we wrote above, which calls the second function we wrote to do the categorization\n",
    "data = add_snowfall_category(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the data using the fourth function we wrote\n",
    "summary = summarize_data(data)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and using your own module\n",
    "\n",
    "Finally, if you find yourself using functions you wrote on a regular basis, you might want to put them in a `.py` file you can import just like we import `Numpy` or `Pandas`.  Once again based on the example provided by example from [pyOpenSci](https://github.com/pyOpenSci/), the functions we wrote above are all stored in a single Python file called `my_module.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_module import load_data, summarize_data, categorize_snowfall_amount\n",
    "\n",
    "data_path = \"snow_data.csv\"\n",
    "\n",
    "# Load and clean the data\n",
    "data = load_data(data_path)\n",
    "\n",
    "# Add snowfall category\n",
    "data = categorize_snowfall_amount(data)\n",
    "\n",
    "# Summarize the data\n",
    "summary = summarize_data(data)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
